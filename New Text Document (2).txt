!pip install selenium


from selenium import webdriver
from bs4 import BeautifulSoup
import threading
import pandas as pd
import time


filename = "google_data_scrapper"
url = "https://www.google.com/search?q=cafe+in+karachi&biw=1242&bih=568&tbm=lcl&sxsrf=ALeKk03r1h6a8Yp4qcl627BHtIQZOZ_YYA%3A1617554516204&ei=VOxpYKv2C9-BhbIP4qquqAU&oq=hospital+in+is&gs_l=psy-ab.1.0.0l10.1001.4645.0.7753.12.9.3.0.0.0.601.1755.2-1j1j0j2.4.0....0...1c.1.64.psy-ab..6.6.1187...35i39k1j0i67k1.0.nN1od9qadaA#rlfi=hd:;si:;mv:[[33.741605799999995,73.18706569999999],[33.6180301,72.9552866]];tbs:lrf:!1m4!1u3!2m2!3m1!1e1!1m4!1u2!2m2!2m1!1e1!2m1!1e2!2m1!1e3!3sIAE,lf:1,lf_ui:2"



browser = webdriver.Chrome('C:/chromedriver.exe')
record= []
e= []
def Selenium_extractor():
    time.sleep(2)
    a=browser.find_elements_by_class_name("VkpGBb")
    time.sleep(1)
    for i in range(len(a)):
        a[i].click()
        time.sleep(2)
        source=browser.page_source
                                                          #Beautiful soup for scraping the html source
        soup=BeautifulSoup(source,'html.parser')
        try:
            Name_Html=soup.findAll('div',{"class":"SPZz6b"})
            
            name=Name_Html[0].text
            if name not in e:
                e.append(name)
                print(name)
                Phone_Html=soup.findAll('span',{"class":"LrzXr zdqRlf kno-fv"})    
                phone=Phone_Html[0].text
                print(phone)
            
                Address_Html=soup.findAll('span',{"class":"LrzXr"})
                
                address=Address_Html[0].text
                #print(address)
                try:
                    Website_Html=soup.findAll('div',{"class":"QqG1Sd"})
                    web=Website_Html[0].findAll('a')
            
                    website=web[0].get('href')
                except:
                    website="Not available"
                #print(website)
                record.append((name,phone,address,website))
                df=pd.DataFrame(record,columns=['Name','Phone number','Address','Website'])  # writing data to the file
                df.to_csv(filename + '.csv',index=False,encoding='utf-8')

        except:
            print("error")
            continue
            

        
    try:
        time.sleep(1)            
        next_button=browser.find_element_by_id("pnnext")                  # clicking the next button
        next_button.click()
        browser.implicitly_wait(2)
        time.sleep(2)
        Selenium_extractor()
    except:
        print("ERROR occured at clicking net button")

        
browser.get(url) 
time.sleep(10)                                             # pausing the program for 10 secs
Selenium_extractor()

